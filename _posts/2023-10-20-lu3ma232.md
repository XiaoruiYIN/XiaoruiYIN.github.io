---
date: 2023-10-20
layout: post
title: LU3MA232 (1)
subtitle: 
description: 
image: https://raw.githubusercontent.com/XiaoruiYIN/gtiobnsimg/main/img/sb.jpg
optimized_image: https://raw.githubusercontent.com/XiaoruiYIN/gtiobnsimg/main/img/sb.jpg
category: Mathematics
tags:
  - Mathematics
author: X.YIN
math: true
---


> 本文是为了复习数值分析这门课的考试而写的. 这个课程的目标是求ode的数值解. 我显然对这门课没有任何兴趣但这在sbu是没有余地的必修课(尽管其实他也没有任何让你选修的课), 所以为了考试我选择顺从他. 幽默的是在必修课中唯独这门课用到了最多的前置知识, 并且看上去是唯一学完了就能有点用的, 仿佛sbu的全部课程设计就是为了这门课. 不过就目前而言感觉把本课程的全部结论当成黑箱使用不会造成任何问题(这些内容很容易相信是对的), 因此这里基本上就是列出需要的结论, 就算要证明大多数也是基本的古典的分析技巧, 在这个意义下该课程仅有记号, 术语和计算量的困难. 

> 声明: 本文遵循 [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0). 假如您是我的同学, 我私下地请求您不将此笔记分享给该班级来自四川省的且姓氏首字母是前七个罗马字母之一的同学, 即便我并不会以任何方式限制您采取类似的行动.

# Chapitre 1. Schémas à un pas

以下我们把本节标题简称为1P方法. 目标是逼近如下EDO的解

$$y'(t)=f(t,y(t));\ y(0)=y
_
0,$$

其中 $t\in [0,T]$, $f$ 连续在 $[0,T]\times\mathbb{R}^d$. 但是为了方便我们以下全部取 $d=1,T=1$, 这和高维没有任何区别.

如果 $f$ 光滑 (明显过强但是我不知道可以若到) 并且存在正值的连续函数 $\varphi$ 满足 $\mid f(t,y)\mid \geq \varphi(t)(1+\mid y\mid),$ 那么它有唯一的全局的解.

我们分段线性地逼近它. 固定分点数 $N$. 从 $y(0)=y
_
0$ 开始递归地定义一个序列

$$y
_
{n+1}=y
_
n+F(t
_
n,y
_
n,h)$$

其中 $t
_
n=nh;h=1/N.$

$F$ 在 $[0,1]\times\mathbb{R}\times[0,1]$ 连续.

一个1P方法就是指一个 $F$ 的取法. explicite和implicite的1P方法就是字面意思. implicite的情形下 $F$ 被换成 $\Phi(t
_
n,t
_
{n+1}
,y
_
n,y
_
{n+1},h)$, 并且当然会需要更多的条件来保证这玩意确实能良定义. 

利用压缩映射的不动点定理会有

**Prop.** 设 $\Phi$ 在 $y
_
{n+1}$ 位置对其他变量一致Lip并且一个Lip的常数是 $L$, 那么 $h<1/L$ 时此方法良定义.

> schéma一词是阳性的, explicite这两个词天生以e结尾. 

以下的stable+consistant的收敛判准对于implicite也对, 和explicite完全类似. 我们只叙述后者.

1P方法收敛是字面意思.

**Def** 1P方法 **stable** 是指假如我们给每一步一个扰动, 那么递归出来的序列变化也不会太大, 这避免出现那种快速震荡的情况. 精确地说是存在常数 $C$, 任意地定义

$$z
_
0=y
_
0+\eta
_
0;z
_
{n+1}=z
_
n+F(t
_
n,z
_
n,h)+\eta
_
n$$

都会有

$$\mid z
_
n-y
_
n\mid\leq C\sum
_
{i=0}^{N-1}\mid\eta
_i\mid.$$

**Critère.** 如果 $F$ 一致地对于 $y$ 位置的变量Lip, 那么这个方法stable.

令 $$\epsilon
_
n=y(t
_
{n+1})=y(t
_
n)+F(t
_
n,y(t
_
n),h)

**Def** 1P方法 **consistant** 是指 $\sum
_
{i=0}^N\mid \epsilon
_
i\mid$ 随着 $N$ 收敛到0.

**Critère.** 如果 $F(t,y,0)=f(t,y)$ 那这个1P方法 consistant.

注意以上两个判准都只需要 $f$ 和 $F$连续.

**Th.** 一个方法consistant且stable则它收敛.

**Def.** 存在常数 $C$ 使得任何 $N$ 有 $\sum
_
{i=0}^{N-1}\mid \epsilon
_
i\mid \leq Ch^p$ 则称一个方法是至少 $p$ 阶. 这里 $p$ 是整数.

**Prop.** 如果有 $C
_
1$ 使得对每个n $\epsilon
_
n\mid \leq Ch^{p+1}$ 那么这方法至少 $p$ 阶; 如果还有 $C
_
2$ 使得对每个n $\epsilon
_
n\mid \geq Ch^{p+1}$ 那么这方法就是 $p$ 阶.

下面定义两个来自于直接的几何直观的explicite的方法, 都收敛

**Euler Explicite** $F(t,y,h)=f(t,y).$ 当 $f\in\mathscr{C}^1$, ordre 1.

**Euler modifié** $F(t,y,h)=f(t\frac 2h,y+\frac2h f(t,y)).$ $f\in\mathscr{C}^2$, ordre 2.

以及两个implicite

**Euler Implicite** $\Phi(t
_
n,t
_
{n+1}
,y
_
n,y
_
{n+1},h)=f(t
_
{n+1},y
_
{n+1}),$ ordre 1.

**Crank-Nicolson** $\Phi(t
_
n,t
_
{n+1}
,y
_
n,y
_
{n+1},h)=\frac 12 (f(t
_
n,y
_
n)+f(t
_
{n+1},y
_
{n+1})),$ ordre 2.

因为这是用来算的, 所以我们接下来的问题就是对于implicite方法如何计算出这个 $y
_
{n+1}$. 我们的办法是用逼近零点的Newton方法.


# Chapitre 2. Méthode de Newton

1维情况是我们非常熟悉的. 设 $g$ 是某一区间的至少 $\mathscr{C}^1$ 函数并且具有零点 $c$. 我们任取 $x_0$ 并且定义 $$x
_
{n+1}=x
_
n-\frac{g(x
_
n)}{g'(x
_
n)}.$$

可以想见 $g$ 的形状比较好看的时候这个序列迅速收敛到 $a$. 

**Prop.** 设对某个 $r>0$ 在 $[c-r,c+r]$ 上 $g\in\mathscr{C}^2$, 并且 $g'\neq 0$. 那么只要起始的点落在 $[c-\alpha,c+\alpha]$ 时, 就有
$$\mid x
_
n-c\mid\leq K(\frac 1K\mid x
_
0-c\mid)^{2^n},$$
其中 $K=2\mathrm{min}\mid g'\mid/\mathrm{max}\mid g''\mid, \alpha=\mathrm{min}(r,K).$

但是因为我们在先前允许 $y$ 是个高维的, 所以也需要考虑 $g$ 是向量值函数的情况. 这个向量值函数导数是个矩阵. 所以我们把递推改为

$$x
_
{n+1}=x
_
n-(\nabla g(x
_
n))^{-1}g(x
_
n).$$

因为 $\mathrm{GL}
_
d(\mathbb{R})$ 是 $M
_
d(\mathbb{R})$ 的开子群, 当 $\nabla g(c)$ 可逆时可以想像只要 $x$ 距离 $c$ 足够近那么 $\nabla g(c)$ 也可逆, 所以这个序列定义良好. 如果又有 $g\in\mathscr{C}^2$ 的时候也有类似1维时的 $C^{2^n}$ 级别的收敛.

剩下的内容是证明为什么这方法对于以上的 schéma implicite 的确奏效, 这部分也直接承认它. 

# Chapitre 3. Analyse numérique matricielle

本节的目的是对给定的实矩阵 $A\in M
_
N(\mathbb{R})$ 和 $B\in \mathbb{R}^N$ 解方程组 $Y$ 使得 $AY=B$. 

> 需要说明的是这一节我不知道他要干什么, 我也完全没能理解他的motivation哪里motivé. 另外他大量假定了矩阵 $A$ 是正定的, 但是我寻思判断一个矩阵正定本身也需要不少计算并且你随便写下一个方程组它也很难正定, 也许我们可以给自己一个心理安慰是实际操作当中会遇到很多正定矩阵.

**1. Méthodes directes**

这个所谓离散方法的意思是有限步内就终止的操作. 第一种是最直接的用Gauss消去或者 $LU$ 分解(这两个单纯从理论上看我感觉跟直接求逆没差,但我并不知道它们实际操作起来复杂度是不是一样).

第二个叫做Cholesky分解. 这个事情在 $A$ 正定的情况下有效.

**Prop.** 设 $A$ 正定. 那么有唯一的严格正对角线的上三角矩阵 $H$ 使得 $A=H^TH.$

证明也是纯纯的在左下角打洞然后归纳. 

顺便一提以上两个他都把分解后的矩阵给用原来矩阵的元素显式地写出来了, 感觉也没什么记下来的价值. 

**2. Méthodes itératives**

这节假定了矩阵 $A$ 正定. 我们旨在不计算 $A$ 的逆而直接获得 $Y$ 的近似解. 办法是将该问题转化成变分问题, 然后使用梯度下降法找到这个最小值.

这是转化成变分问题. 注意下面定义的 $J$ 是个多项式所, 所以下面的证明可以乱做.

**Prop.** 考虑实函数 $J:X\mapsto 0.5X^TAX-B^TX,$ 我们有

$AY=B\Leftrightarrow J(Y)=\mathrm{inf}
_
{X\in\mathbb{R}^N}J(X).$

接下来是根据所谓 méthode du gradient 寻求 $J$ 的最小值. 这个梯度下降就是不断顺着梯度(减小最快)的方向走. 因此倒是容易相信它有效.

具体操作. 首先对 $J$ 求导. 我们有 $J(Y+tX)=J(Y)+t(AY-B)^TX+o(t^2X^2).$

任取 $Y
_
0$. 令 $r
_
n=AY
_
n-B.$ 如果某个(梯度方向) $r
_
n=0$ 那事情就做完了. 若不然, 待定 $t$ 令 $Y
_
{n+1}=Y
_
n-tr
_
n,$ 算一下会知道 $Y-Y
_
{n+1}=(I-tA)(Y-Y
_
n).$ 所以 $Y-Y
_
n=(I-tA)^n(Y-Y
_
0).$ 因此只要选择恰当的 $t$ 使得那个矩阵的谱半径小于1就得到这个方法收敛. 他这里用差不多的办法给出了这个方法收敛的充分必要条件(因为对于 $A$ 对称, $\mathrm{lim}
_
{n\to\infty}A^nX$ 成立对于任何 $X$ 当且仅当 $A$ 的谱半径小于1).

**Prop.** $A$ 正定. (依赖于 $t$ 产生的) 序列 $(Y
_
n)
_
{n\in\mathbb{N}}$ 无论如何选取起始点都能收敛到真实解 $Y$ 当且仅当 $I-tA$ 的谱半径小于1. 进一步, 选择 $t=2/(\lambda
_
1+\lambda
_
2)$ 时达到最快收敛速度, 其中 $\lambda
_
1+\lambda
_
2$ 是 $A$ 的最大和最小特征值. 

> 有一说一我老百姓不懂对于计算机来说这样真的比直接算 $A$ 的逆要快吗;;



全文耗时约5小时, 我这门课的期中复习就做到这里. 

此课程期末考试之前应该会有(2).

本文不收录于 BNSNote 系列因为笔者认为这会破坏其纯洁性.
